{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c40048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "class Scaler():\n",
    "    # hint: https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/\n",
    "    def __init__(self):\n",
    "        raise NotImplementedError\n",
    "    def __call__(self,features, is_train=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def get_features(csv_path,is_train=False,scaler=None):\n",
    "    '''\n",
    "    Description:\n",
    "    read input feature columns from csv file\n",
    "    manipulate feature columns, create basis functions, do feature scaling etc.\n",
    "    return a feature matrix (numpy array) of shape m x n \n",
    "    m is number of examples, n is number of features\n",
    "    return value: numpy array\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    csv_path: path to csv file\n",
    "    is_train: True if using training data (optional)\n",
    "    scaler: a class object for doing feature scaling (optional)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    help:\n",
    "    useful links: \n",
    "        * https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "        * https://www.geeksforgeeks.org/python-read-csv-using-pandas-read_csv/\n",
    "    '''\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "def get_targets(csv_path):\n",
    "    '''\n",
    "    Description:\n",
    "    read target outputs from the csv file\n",
    "    return a numpy array of shape m x 1\n",
    "    m is number of examples\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "     \n",
    "\n",
    "def analytical_solution(feature_matrix, targets, C=0.0):\n",
    "    '''\n",
    "    Description:\n",
    "    implement analytical solution to obtain weights\n",
    "    as described in lecture 5d\n",
    "    return value: numpy array\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    targets: numpy array of shape m x 1\n",
    "    '''\n",
    "\n",
    "    raise NotImplementedError \n",
    "\n",
    "def get_predictions(feature_matrix, weights):\n",
    "    '''\n",
    "    description\n",
    "    return predictions given feature matrix and weights\n",
    "    return value: numpy array\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    '''\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "def mse_loss(feature_matrix, weights, targets):\n",
    "    '''\n",
    "    Description:\n",
    "    Implement mean squared error loss function\n",
    "    return value: float (scalar)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    targets: numpy array of shape m x 1\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "\n",
    "def l2_regularizer(weights):\n",
    "    '''\n",
    "    Description:\n",
    "    Implement l2 regularizer\n",
    "    return value: float (scalar)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments\n",
    "    weights: numpy array of shape n x 1\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "\n",
    "def loss_fn(feature_matrix, weights, targets, C=0.0):\n",
    "    '''\n",
    "    Description:\n",
    "    compute the loss function: mse_loss + C * l2_regularizer\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    targets: numpy array of shape m x 1\n",
    "    C: weight for regularization penalty\n",
    "    return value: float (scalar)\n",
    "    '''\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "def compute_gradients(feature_matrix, weights, targets, C=0.0):\n",
    "    '''\n",
    "    Description:\n",
    "    compute gradient of weights w.r.t. the loss_fn function implemented above\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    targets: numpy array of shape m x 1\n",
    "    C: weight for regularization penalty\n",
    "    return value: numpy array\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "\n",
    "def sample_random_batch(feature_matrix, targets, batch_size):\n",
    "    '''\n",
    "    Description\n",
    "    Batching -- Randomly sample batch_size number of elements from feature_matrix and targets\n",
    "    return a tuple: (sampled_feature_matrix, sampled_targets)\n",
    "    sampled_feature_matrix: numpy array of shape batch_size x n\n",
    "    sampled_targets: numpy array of shape batch_size x 1\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    targets: numpy array of shape m x 1\n",
    "    batch_size: int\n",
    "    '''    \n",
    "    raise NotImplementedError\n",
    "    \n",
    "def initialize_weights(n):\n",
    "    '''\n",
    "    Description:\n",
    "    initialize weights to some initial values\n",
    "    return value: numpy array of shape n x 1\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments\n",
    "    n: int\n",
    "    '''\n",
    "    raise NotImplementedError\n",
    "\n",
    "def update_weights(weights, gradients, lr):\n",
    "    '''\n",
    "    Description:\n",
    "    update weights using gradient descent\n",
    "    retuen value: numpy matrix of shape nx1\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    # weights: numpy matrix of shape nx1\n",
    "    # gradients: numpy matrix of shape nx1\n",
    "    # lr: learning rate\n",
    "    '''    \n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "def early_stopping(arg_1=None, arg_2=None, arg_3=None, arg_n=None):\n",
    "    # allowed to modify argument list as per your need\n",
    "    # return True or False\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "def plot_trainsize_losses():\n",
    "    '''\n",
    "    Description:\n",
    "    plot losses on the development set instances as a function of training set size \n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    # you are allowed to change the argument list any way you like \n",
    "    '''    \n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def do_gradient_descent(train_feature_matrix,  \n",
    "                        train_targets, \n",
    "                        dev_feature_matrix,\n",
    "                        dev_targets,\n",
    "                        lr=1.0,\n",
    "                        C=0.0,\n",
    "                        batch_size=32,\n",
    "                        max_steps=10000,\n",
    "                        eval_steps=5):\n",
    "    '''\n",
    "    feel free to significantly modify the body of this function as per your needs.\n",
    "    ** However **, you ought to make use of compute_gradients and update_weights function defined above\n",
    "    return your best possible estimate of LR weights\n",
    "\n",
    "    a sample code is as follows -- \n",
    "    '''\n",
    "    weights = initialize_weights(n)\n",
    "    dev_loss = mse_loss(dev_feature_matrix, weights, dev_targets)\n",
    "    train_loss = mse_loss(train_feature_matrix, weights, train_targets)\n",
    "\n",
    "    print(\"step {} \\t dev loss: {} \\t train loss: {}\".format(0,dev_loss,train_loss))\n",
    "    for step in range(1,max_steps+1):\n",
    "\n",
    "        #sample a batch of features and gradients\n",
    "        features,targets = sample_random_batch(train_feature_matrix,train_targets,batch_size)\n",
    "        \n",
    "        #compute gradients\n",
    "        gradients = compute_gradients(features, weights, targets, C)\n",
    "        \n",
    "        #update weights\n",
    "        weights = update_weights(weights, gradients, lr)\n",
    "\n",
    "        if step%eval_steps == 0:\n",
    "            dev_loss = mse_loss(dev_feature_matrix, weights, dev_targets)\n",
    "            train_loss = mse_loss(train_feature_matrix, weights, train_targets)\n",
    "            print(\"step {} \\t dev loss: {} \\t train loss: {}\".format(step,dev_loss,train_loss))\n",
    "\n",
    "        '''\n",
    "        implement early stopping etc. to improve performance.\n",
    "        '''\n",
    "\n",
    "    return weights\n",
    "\n",
    "def do_evaluation(feature_matrix, targets, weights):\n",
    "    # your predictions will be evaluated based on mean squared error \n",
    "    predictions = get_predictions(feature_matrix, weights)\n",
    "    loss =  mse_loss(feature_matrix, weights, targets)\n",
    "    return loss\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scaler = Scaler() #use of scaler is optional\n",
    "    train_features, train_targets = get_features('data/train.csv',True,scaler), get_targets('data/train.csv')\n",
    "    dev_features, dev_targets = get_features('data/dev.csv',False,scaler), get_targets('data/dev.csv')\n",
    "\n",
    "    a_solution = analytical_solution(train_features, train_targets, C=1e-8)\n",
    "    print('evaluating analytical_solution...')\n",
    "    dev_loss=do_evaluation(dev_features, dev_targets, a_solution)\n",
    "    train_loss=do_evaluation(train_features, train_targets, a_solution)\n",
    "    print('analytical_solution \\t train loss: {}, dev_loss: {} '.format(train_loss, dev_loss))\n",
    "\n",
    "    print('training LR using gradient descent...')\n",
    "    gradient_descent_soln = do_gradient_descent(train_features, \n",
    "                        train_targets, \n",
    "                        dev_features,\n",
    "                        dev_targets,\n",
    "                        lr=1.0,\n",
    "                        C=0.0,\n",
    "                        batch_size=32,\n",
    "                        max_steps=2000000,\n",
    "                        eval_steps=5)\n",
    "\n",
    "    print('evaluating iterative_solution...')\n",
    "    dev_loss=do_evaluation(dev_features, dev_targets, gradient_descent_soln)\n",
    "    train_loss=do_evaluation(train_features, train_targets, gradient_descent_soln)\n",
    "    print('gradient_descent_soln \\t train loss: {}, dev_loss: {} '.format(train_loss, dev_loss))\n",
    "    #plot_trainsize_losses()   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
