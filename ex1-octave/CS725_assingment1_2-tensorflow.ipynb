{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b471107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "class Scaler():\n",
    "    # hint: https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/\n",
    "    def __init__(self):\n",
    "        self.min=None\n",
    "        self.max=None\n",
    "    def __call__(self,features, is_train=False):\n",
    "        m=np.size(feature_matrix,0)\n",
    "        n=np.size(feature_matrix,1)\n",
    "        if is_train:\n",
    "            self.min = np.min(features,axis=0,keepdims=True)\n",
    "            self.max = np.min(features,axis=0,keepdims=True)\n",
    "            \n",
    "        assert self.min is not None and self.max is not None\n",
    "        featurse = (features - self.min)/(self.max-self.min + 1e-20)\n",
    "        ones = np.ones[m,1]\n",
    "        features = np.concatenate([ones,features],1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ba7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(csv_path,is_train=False,scaler=None):\n",
    "    '''\n",
    "    Description:\n",
    "    read input feature columns from csv file\n",
    "    manipulate feature columns, create basis functions, do feature scaling etc.\n",
    "    return a feature matrix (numpy array) of shape m x n \n",
    "    m is number of examples, n is number of features\n",
    "    return value: numpy array\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    csv_path: path to csv file\n",
    "    is_train: True if using training data (optional)\n",
    "    scaler: a class object for doing feature scaling (optional)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    help:\n",
    "    useful links: \n",
    "        * https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "        * https://www.geeksforgeeks.org/python-read-csv-using-pandas-read_csv/\n",
    "    '''\n",
    "    data = pd.read_csv(csv_path)\n",
    "    Satellite = {'Terra': 1,'Aqua': 2}\n",
    "    data.satellite = [Satellite[item] for item in data.satellite]\n",
    "    Daynight = {'D': 1,'N': 2}\n",
    "    data.daynight = [Daynight[item] for item in data.daynight]\n",
    "    data1 = data.to_numpy()\n",
    "    df1 = data.loc[:, [\"acq_date\"]]\n",
    "    df1['year'] = pd.DatetimeIndex(df1['acq_date']).year\n",
    "    df1['month'] = pd.DatetimeIndex(df1['acq_date']).month\n",
    "    df=df1.to_numpy()\n",
    "    data = data1[:,1:6]\n",
    "    data = np.column_stack((data, df[:,1:3]))\n",
    "    data = np.column_stack((data, data1[:,7]))\n",
    "    data = np.column_stack((data, data1[:,8]))\n",
    "    data = np.column_stack((data, data1[:,10]))\n",
    "    data = np.column_stack((data, data1[:,12]))\n",
    "    data = np.column_stack((data, data1[:,14]))\n",
    "    data=data.astype(float)\n",
    "    #data = np.column_stack((data, data1[:,-1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec8314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(csv_path):\n",
    "    '''\n",
    "    Description:\n",
    "    read target outputs from the csv file\n",
    "    return a numpy array of shape m x 1\n",
    "    m is number of examples\n",
    "    '''\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data=data['frp']\n",
    "    m=len(data)\n",
    "    data = data.to_numpy()\n",
    "    data = data.astype(float)\n",
    "    data= data.reshape(m,1) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b34c07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_solution(feature_matrix, targets, C=0.0):\n",
    "    '''\n",
    "    Description:\n",
    "    implement analytical solution to obtain weights\n",
    "    as described in lecture 5d\n",
    "    return value: numpy array\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    targets: numpy array of shape m x 1\n",
    "    '''\n",
    "    m, n = np.shape(feature_matrix)\n",
    "    feature_matrix = np.hstack((np.ones((m, 1)), feature_matrix))\n",
    "    w = np.matmul(feature_matrix.T,feature_matrix) + C * np.eye(n)\n",
    "    w = np.matmul(np.linalg.inv(w),feature_matrix.T)\n",
    "    w = np.matmul(w,targets)\n",
    "    return w    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3f56b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(feature_matrix, weights):\n",
    "    '''\n",
    "    description\n",
    "    return predictions given feature matrix and weights\n",
    "    return value: numpy array\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    '''\n",
    "    m=np.size(feature_matrix,0)\n",
    "    n=np.size(feature_matrix,1)\n",
    "    feature_matrix = np.column_stack((np.ones(m).T,feature_matrix))\n",
    "    predictions = np.matmul(feature_matrix,weights)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34d53525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(feature_matrix, weights, targets):\n",
    "    '''\n",
    "    Description:\n",
    "    Implement mean squared error loss function\n",
    "    return value: float (scalar)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    targets: numpy array of shape m x 1\n",
    "    '''\n",
    "    loss = np.square(np.matmul(feature_matrix,weights) - targets)\n",
    "    loss = np.mean(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3835abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularizer(weights):\n",
    "    '''\n",
    "    Description:\n",
    "    Implement l2 regularizer\n",
    "    return value: float (scalar)\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments\n",
    "    weights: numpy array of shape n x 1\n",
    "    '''\n",
    "    w_regularized = np.sum(np.square(weights))\n",
    "    return w_regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0901eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(feature_matrix, weights, targets, C=0.0):\n",
    "    '''\n",
    "    Description:\n",
    "    compute the loss function: mse_loss + C * l2_regularizer\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    targets: numpy array of shape m x 1\n",
    "    C: weight for regularization penalty\n",
    "    return value: float (scalar)\n",
    "    '''\n",
    "    loss = mse_loss(feature_matrix, weights, targets) + C*l2_regularizer(weights)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e01df738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(feature_matrix, weights, targets, C=0.0):\n",
    "    '''\n",
    "    Description:\n",
    "    compute gradient of weights w.r.t. the loss_fn function implemented above\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    weights: numpy array of shape n x 1\n",
    "    targets: numpy array of shape m x 1\n",
    "    C: weight for regularization penalty\n",
    "    return value: numpy array\n",
    "    '''\n",
    "    m=np.size(feature_matrix,0)\n",
    "    n=np.size(feature_matrix,1)\n",
    "    term1 = np.matmul(feature_matrix.T,(get_predictions(feature_matrix, weights)-targets))\n",
    "    term2 = C*weights\n",
    "    gradients = 2*((term1/m)+term2)\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "006ff1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_batch(feature_matrix, targets, batch_size):\n",
    "    '''\n",
    "    Description\n",
    "    Batching -- Randomly sample batch_size number of elements from feature_matrix and targets\n",
    "    return a tuple: (sampled_feature_matrix, sampled_targets)\n",
    "    sampled_feature_matrix: numpy array of shape batch_size x n\n",
    "    sampled_targets: numpy array of shape batch_size x 1\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    feature_matrix: numpy array of shape m x n\n",
    "    targets: numpy array of shape m x 1\n",
    "    batch_size: int\n",
    "    '''    \n",
    "    index = np.random.randint(0,len(feature_matrix),batch_size)\n",
    "    X_tmp = np.array([feature_matrix[i] for i in index])\n",
    "    y_tmp = np.array([targets[i] for i in index])\n",
    "    return(X_tmp,y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55ba1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(n):\n",
    "    '''\n",
    "    Description:\n",
    "    initialize weights to some initial values\n",
    "    return value: numpy array of shape n x 1\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments\n",
    "    n: int\n",
    "    '''\n",
    "    w_tmp = np.random.uniform(0,0.01,(n+1,1))\n",
    "    return w_tmp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "486f48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, gradients, lr):\n",
    "    '''\n",
    "    Description:\n",
    "    update weights using gradient descent\n",
    "    retuen value: numpy matrix of shape nx1\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    # weights: numpy matrix of shape nx1\n",
    "    # gradients: numpy matrix of shape nx1\n",
    "    # lr: learning rate\n",
    "    '''    \n",
    "    weights = weights - lr*gradients\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0de2de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(patience, step, patience_threshold, min_steps):\n",
    "    # allowed to modify argument list as per your need\n",
    "    # return True or False\n",
    "     if step < min_steps:\n",
    "        return False\n",
    "        if patience >= patience_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f6c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trainsize_losses():\n",
    "    '''\n",
    "    Description:\n",
    "    plot losses on the development set instances as a function of training set size \n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    Arguments:\n",
    "    # you are allowed to change the argument list any way you like \n",
    "    '''    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1719234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_gradient_descent(train_feature_matrix,  \n",
    "                        train_targets, \n",
    "                        dev_feature_matrix,\n",
    "                        dev_targets,\n",
    "                        lr=1.0,\n",
    "                        C=0.0,\n",
    "                        batch_size=32,\n",
    "                        max_steps=10000,\n",
    "                        eval_steps=5):\n",
    "    '''\n",
    "    feel free to significantly modify the body of this function as per your needs.\n",
    "    ** However **, you ought to make use of compute_gradients and update_weights function defined above\n",
    "    return your best possible estimate of LR weights\n",
    "\n",
    "    a sample code is as follows -- \n",
    "    '''\n",
    "    m=np.size(train_feature_matrix,0)\n",
    "    n=np.size(train_feature_matrix,1)\n",
    "    weights = initialize_weights(n)\n",
    "    dev_loss = mse_loss(dev_feature_matrix, weights, dev_targets)\n",
    "    train_loss = mse_loss(train_feature_matrix, weights, train_targets)\n",
    "    #best_dev_loss = dev_loss\n",
    "    #best_weights = weights\n",
    "    #patience = 0\n",
    "\n",
    "    print(\"step {} \\t dev loss: {} \\t train loss: {}\".format(0,dev_loss,train_loss))\n",
    "    for step in range(1,max_steps+1):\n",
    "\n",
    "        #sample a batch of features and gradients\n",
    "        features,targets = sample_random_batch(train_feature_matrix,train_targets,batch_size)\n",
    "        \n",
    "        #compute gradients\n",
    "        gradients = compute_gradients(features, weights, targets, C)\n",
    "        \n",
    "        #update weights\n",
    "        weights = update_weights(weights, gradients, lr)\n",
    "\n",
    "        if step%eval_steps == 0:\n",
    "            dev_loss = mse_loss(dev_feature_matrix, weights, dev_targets)\n",
    "            train_loss = mse_loss(train_feature_matrix, weights, train_targets)\n",
    "            print(\"step {} \\t dev loss: {} \\t train loss: {}\".format(step,dev_loss,train_loss))\n",
    "\n",
    "        '''\n",
    "        implement early stopping etc. to improve performance.\n",
    "        \n",
    "        '''\n",
    "        if step%eval_steps == 0:\n",
    "            dev_loss = mse_loss(dev_feature_matrix, weights, dev_targets)\n",
    "            train_loss = mse_loss(train_feature_matrix, weights, train_targets)\n",
    "            print(\"step {} \\t dev loss: {} \\t train loss: {}\".format(step,dev_loss,train_loss))\n",
    "            '''\n",
    "            if dev_loss < best_dev_loss:\n",
    "                patience = 0\n",
    "                best_dev_loss = dev_loss\n",
    "                best_weights = weights\n",
    "            else:\n",
    "                patience +=1\n",
    "                if early_stopping(patience,step,patience_threshold=1000,min_steps=(2*m)/batch_size):\n",
    "                    print('Stopping Early at step: {}'.format(step))\n",
    "                    break\n",
    "        '''\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b877ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_evaluation(feature_matrix, targets, weights):\n",
    "    predictions = get_predictions(feature_matrix, weights)\n",
    "    loss =  mse_loss(feature_matrix, weights, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3faa0e6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features\n",
      "dev features\n",
      "analytical solution\n",
      "(12, 1)\n",
      "(25001, 12)\n",
      "m: 25001\n",
      "n: 12\n",
      "weights: (13, 1)\n",
      "feature_matrix: (25001, 13)\n",
      "predictions: (25001, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59858.74143893175"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = Scaler() #use of scaler is optional\n",
    "path = 'C:/Users/bhara/Documents/desk/MachineLearning/CS725/Assingment_01/cs725-2021a-assgmt1'\n",
    "print('train features')\n",
    "train_features, train_targets = get_features(path + '/train.csv',True), get_targets(path + '/train.csv')\n",
    "print('dev features')\n",
    "dev_features, dev_targets = get_features(path + '/dev.csv',False), get_targets(path + '/dev.csv')\n",
    "print('analytical solution')\n",
    "a_solution = analytical_solution(train_features, train_targets, C=1e-8)\n",
    "print(a_solution.shape)\n",
    "#train_loss=do_evaluation(train_features, train_targets, a_solution)\n",
    "feature_matrix = train_features\n",
    "print(feature_matrix.shape)\n",
    "m=np.size(feature_matrix,0)\n",
    "print(\"m:\",m)\n",
    "n=np.size(feature_matrix,1)\n",
    "print(\"n:\",n)\n",
    "weights = initialize_weights(n)\n",
    "print(\"weights:\",weights.shape)\n",
    "feature_matrix = np.column_stack((np.ones(m).T,feature_matrix))\n",
    "print(\"feature_matrix:\",feature_matrix.shape)\n",
    "predictions = np.matmul(feature_matrix,weights)\n",
    "print(\"predictions:\",predictions.shape)\n",
    "loss =  mse_loss(feature_matrix, weights, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "468bd08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features\n",
      "dev features\n",
      "analytical solution\n",
      "evaluating analytical_solution...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 12 is different from 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-1693fa5156c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0ma_solution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalytical_solution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluating analytical_solution...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdev_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_solution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_solution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'analytical_solution \\t train loss: {}, dev_loss: {} '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-9ea5a367bcc2>\u001b[0m in \u001b[0;36mdo_evaluation\u001b[1;34m(feature_matrix, targets, weights)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdo_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-f603c4b9dbff>\u001b[0m in \u001b[0;36mget_predictions\u001b[1;34m(feature_matrix, weights)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfeature_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 12 is different from 13)"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    scaler = Scaler() #use of scaler is optional\n",
    "    path = 'C:/Users/bhara/Documents/desk/MachineLearning/CS725/Assingment_01/cs725-2021a-assgmt1'\n",
    "    print('train features')\n",
    "    train_features, train_targets = get_features(path + '/train.csv',True), get_targets(path + '/train.csv')\n",
    "    print('dev features')\n",
    "    dev_features, dev_targets = get_features(path + '/dev.csv',False), get_targets(path + '/dev.csv')\n",
    "    print('analytical solution')\n",
    "    a_solution = analytical_solution(train_features, train_targets, C=1e-8)\n",
    "    print('evaluating analytical_solution...')\n",
    "    dev_loss=do_evaluation(dev_features, dev_targets, a_solution)\n",
    "    train_loss=do_evaluation(train_features, train_targets, a_solution)\n",
    "    print('analytical_solution \\t train loss: {}, dev_loss: {} '.format(train_loss, dev_loss))\n",
    "\n",
    "    print('training LR using gradient descent...')\n",
    "    gradient_descent_soln = do_gradient_descent(train_features, \n",
    "                        train_targets, \n",
    "                        dev_features,\n",
    "                        dev_targets,\n",
    "                        lr=1.0,\n",
    "                        C=0.001,\n",
    "                        batch_size=32,\n",
    "                        max_steps=200000,\n",
    "                        eval_steps=5)\n",
    "\n",
    "    print('evaluating iterative_solution...')\n",
    "    dev_loss=do_evaluation(dev_features, dev_targets, gradient_descent_soln)\n",
    "    train_loss=do_evaluation(train_features, train_targets, gradient_descent_soln)\n",
    "    print('gradient_descent_soln \\t train loss: {}, dev_loss: {} '.format(train_loss, dev_loss))\n",
    "    #plot_trainsize_losses()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc3061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2c7638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features\n",
      "dev features\n",
      "analytical solution\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/bhara/Documents/desk/MachineLearning/CS725/Assingment_01/cs725-2021a-assgmt1'\n",
    "print('train features')\n",
    "train_features, train_targets = get_features(path + '/train.csv',True), get_targets(path + '/train.csv')\n",
    "print('dev features')\n",
    "dev_features, dev_targets = get_features(path + '/dev.csv',False), get_targets(path + '/dev.csv')\n",
    "print('analytical solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "199ee793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-25.117, 149.245, 363.1  , ..., 100.   , 316.6  ,   1.   ],\n",
       "       [-32.263, 123.294, 349.3  , ...,  95.   , 307.2  ,   1.   ],\n",
       "       [-36.918, 146.782, 336.7  , ..., 100.   , 293.9  ,   2.   ],\n",
       "       ...,\n",
       "       [-28.895, 128.98 , 322.5  , ..., 100.   , 303.   ,   2.   ],\n",
       "       [-34.925, 150.489, 316.9  , ...,  94.   , 296.1  ,   2.   ],\n",
       "       [-28.457, 128.735, 357.3  , ...,  96.   , 317.4  ,   1.   ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd60005e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (13,13) (12,12) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-c7462a797faa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma_solution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalytical_solution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma_solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-881ed474f5a7>\u001b[0m in \u001b[0;36manalytical_solution\u001b[1;34m(feature_matrix, targets, C)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfeature_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (13,13) (12,12) "
     ]
    }
   ],
   "source": [
    "a_solution = analytical_solution(train_features, train_targets, C=1e-8)\n",
    "a_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fb7948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol=np.matmul(dev_features,a_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59869511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4001, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a94383d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[279.57430413],\n",
       "       [ 40.08955047],\n",
       "       [ 12.66079577],\n",
       "       ...,\n",
       "       [-66.01352996],\n",
       "       [ 11.27644315],\n",
       "       [ 13.07262517]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "015176b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39055.12661285697"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = np.mean(np.square(sol - dev_targets))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a10ce965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols(X, y, fit_intercept=True):\n",
    "    \"\"\"Ordinary Least Squares (OLS) Regression model with intercept term.\n",
    "    Fits an OLS regression model using the closed-form OLS estimator equation.\n",
    "    Intercept term is included via design matrix augmentation.\n",
    "    Params:\n",
    "        X - NumPy matrix, size (N, p), of numerical predictors\n",
    "        y - NumPy array, length N, of numerical response\n",
    "        fit_intercept - Boolean indicating whether to include an intercept term\n",
    "    Returns:\n",
    "        NumPy array, length p + 1, of fitted model coefficients\n",
    "    \"\"\"\n",
    "    m, n = np.shape(X)\n",
    "    if fit_intercept:\n",
    "        X = np.hstack((np.ones((m, 1)), X))\n",
    "    return np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8046c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_2 = ols(train_features, train_targets, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d5be83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.21445991e+05],\n",
       "       [-4.75242181e-01],\n",
       "       [ 4.47925513e-01],\n",
       "       [ 6.80872714e+00],\n",
       "       [ 4.05248334e+01],\n",
       "       [ 1.37303182e+02],\n",
       "       [-6.15538269e+01],\n",
       "       [-5.34613598e+00],\n",
       "       [ 6.54181968e-03],\n",
       "       [-3.21911507e+00],\n",
       "       [-1.38864074e+00],\n",
       "       [ 1.02301260e+00],\n",
       "       [ 1.19874699e+02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9f1f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = np.shape(dev_features)\n",
    "X = np.hstack((np.ones((m, 1)), dev_features))\n",
    "sol=np.matmul(X,sol_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f07ff09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[278.44279953],\n",
       "       [ 38.78666831],\n",
       "       [ 10.28515989],\n",
       "       ...,\n",
       "       [-71.31674613],\n",
       "       [ 10.12821476],\n",
       "       [  9.14312166]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "565a76b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39051.43309839717"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = np.mean(np.square(sol - dev_targets))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3345ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
